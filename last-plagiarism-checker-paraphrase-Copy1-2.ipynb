{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e90c5fe7-d2ec-4577-b848-ae534c943777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch==8.11 in ./anaconda3/lib/python3.10/site-packages (8.11.0)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in ./anaconda3/lib/python3.10/site-packages (from elasticsearch==8.11) (8.4.0)\n",
      "Requirement already satisfied: certifi in ./anaconda3/lib/python3.10/site-packages (from elastic-transport<9,>=8->elasticsearch==8.11) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<2,>=1.26.2 in ./anaconda3/lib/python3.10/site-packages (from elastic-transport<9,>=8->elasticsearch==8.11) (1.26.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install elasticsearch==8.11 #Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c29119c-297d-44bf-b892-4d880bd91951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip -q install eland elasticsearch sentence_transformers transformers torch==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaf90bc8-647e-4ada-9aa9-5cb9e60762b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5r/774p5f6x3jb5md2ycsn04blc0000gn/T/ipykernel_4821/3060853836.py:7: DeprecationWarning: Importing from the 'elasticsearch.client' module is deprecated. Instead use 'elasticsearch' module for importing the client.\n",
      "  from elasticsearch.client import MlClient\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from pathlib import Path\n",
    "from eland.ml.pytorch import PyTorchModel\n",
    "from eland.ml.pytorch.transformers import TransformerModel\n",
    "from elasticsearch.client import MlClient\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6907a2bf-4927-428e-9ca8-9df3dd35a2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Elastic Cloud ID:   ········\n",
      "Enter Elastic password:   ········\n"
     ]
    }
   ],
   "source": [
    "# Found in the 'Manage Deployment' page\n",
    "CLOUD_ID = getpass.getpass('Enter Elastic Cloud ID:  ')\n",
    "\n",
    "# Password for the 'elastic' user generated by Elasticsearch\n",
    "ELASTIC_PASSWORD = getpass.getpass('Enter Elastic password:  ')\n",
    "\n",
    "# Create the client instance\n",
    "client = Elasticsearch(\n",
    "    cloud_id=CLOUD_ID,\n",
    "    basic_auth=(\"elastic\", ELASTIC_PASSWORD),\n",
    "    request_timeout=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f6f3f5a-2b93-4a0c-93c8-c887ca80f687",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbb3aaa13344c689154244ceac7cb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eacaff6ae2a94b0fa0d6617f47b81b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base-openai-detector were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "STAGE:2024-01-05 10:28:30 4821:36646 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2024-01-05 10:28:30 4821:36646 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2024-01-05 10:28:30 4821:36646 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61708e4ef3054555b500197b472687e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/476 [00:00<?, ? parts/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'assignment': {'task_parameters': {'model_id': 'roberta-base-openai-detector',\n",
       "   'deployment_id': 'roberta-base-openai-detector',\n",
       "   'model_bytes': 498663890,\n",
       "   'threads_per_allocation': 1,\n",
       "   'number_of_allocations': 1,\n",
       "   'queue_capacity': 1024,\n",
       "   'cache_size': '498663890b',\n",
       "   'priority': 'normal',\n",
       "   'per_deployment_memory_bytes': 498596904,\n",
       "   'per_allocation_memory_bytes': 632532156},\n",
       "  'routing_table': {'2Aa4SRDxTJO2f5b1gRc_4Q': {'current_allocations': 1,\n",
       "    'target_allocations': 1,\n",
       "    'routing_state': 'started',\n",
       "    'reason': ''}},\n",
       "  'assignment_state': 'started',\n",
       "  'start_time': '2024-01-05T15:33:56.506211165Z',\n",
       "  'max_assigned_allocations': 1}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model name from Hugging Face and task type\n",
    "# open ai detector model - developed by open ai https://github.com/openai/gpt-2-output-dataset/tree/master/detector\n",
    "hf_model_id='roberta-base-openai-detector' #updated\n",
    "tm = TransformerModel(model_id=hf_model_id, task_type=\"text_classification\") #updated\n",
    "\n",
    "#set the modelID as it is named in Elasticsearch\n",
    "es_model_id = tm.elasticsearch_model_id()\n",
    "\n",
    "# Download the model from Hugging Face\n",
    "tmp_path = \"models\"\n",
    "Path(tmp_path).mkdir(parents=True, exist_ok=True)\n",
    "model_path, config, vocab_path = tm.save(tmp_path)\n",
    "\n",
    "# Load the model into Elasticsearch\n",
    "ptm = PyTorchModel(client, es_model_id)\n",
    "ptm.import_model(model_path=model_path, config_path=None, vocab_path=vocab_path, config=config)\n",
    "\n",
    "#Start the model\n",
    "s = MlClient.start_trained_model_deployment(client, model_id=es_model_id)\n",
    "s.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85430026-7313-4847-999a-a2ee9af4f3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ef112729e3407a8f4d1c04219605f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-01-05 10:38:32 4821:36646 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2024-01-05 10:38:32 4821:36646 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2024-01-05 10:38:32 4821:36646 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec660ec1eac947c5ab4cbf215fb667e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/416 [00:00<?, ? parts/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'assignment': {'task_parameters': {'model_id': 'sentence-transformers__all-mpnet-base-v2',\n",
       "   'deployment_id': 'sentence-transformers__all-mpnet-base-v2',\n",
       "   'model_bytes': 435655636,\n",
       "   'threads_per_allocation': 1,\n",
       "   'number_of_allocations': 1,\n",
       "   'queue_capacity': 1024,\n",
       "   'cache_size': '435655636b',\n",
       "   'priority': 'normal',\n",
       "   'per_deployment_memory_bytes': 435587600,\n",
       "   'per_allocation_memory_bytes': 700162236},\n",
       "  'routing_table': {'2Aa4SRDxTJO2f5b1gRc_4Q': {'current_allocations': 1,\n",
       "    'target_allocations': 1,\n",
       "    'routing_state': 'started',\n",
       "    'reason': ''}},\n",
       "  'assignment_state': 'started',\n",
       "  'start_time': '2024-01-05T15:43:19.430653116Z',\n",
       "  'max_assigned_allocations': 1}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model name from Hugging Face and task type\n",
    "# sentence-transformers model\n",
    "hf_model_id='sentence-transformers/all-mpnet-base-v2' #updated\n",
    "tm = TransformerModel(model_id=hf_model_id, task_type=\"text_embedding\") #updated\n",
    "\n",
    "#set the modelID as it is named in Elasticsearch\n",
    "es_model_id = tm.elasticsearch_model_id()\n",
    "\n",
    "# Download the model from Hugging Face\n",
    "tmp_path = \"models\"\n",
    "Path(tmp_path).mkdir(parents=True, exist_ok=True)\n",
    "model_path, config, vocab_path = tm.save(tmp_path)\n",
    "\n",
    "# Load the model into Elasticsearch\n",
    "ptm = PyTorchModel(client, es_model_id)\n",
    "ptm.import_model(model_path=model_path, config_path=None, vocab_path=vocab_path, config=config)\n",
    "\n",
    "# Start the model\n",
    "s = MlClient.start_trained_model_deployment(client, model_id=es_model_id)\n",
    "s.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e115bd0-e758-44db-b5b9-96217af472c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'plagiarism-docs'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#source index\n",
    "client.indices.create(\n",
    "index=\"plagiarism-docs\",\n",
    "mappings= {\n",
    "    \"properties\": {\n",
    "        \"title\": {\n",
    "            \"type\": \"text\",\n",
    "            \"fields\": {\n",
    "                \"keyword\": {\n",
    "                \"type\": \"keyword\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"abstract\": {\n",
    "            \"type\": \"text\",\n",
    "            \"fields\": {\n",
    "                \"keyword\": {\n",
    "                \"type\": \"keyword\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"url\": {\n",
    "            \"type\": \"keyword\"\n",
    "        },\n",
    "        \"venue\": {\n",
    "            \"type\": \"keyword\"\n",
    "        },\n",
    "         \"year\": {\n",
    "            \"type\": \"keyword\"\n",
    "        }      \n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6739f55b-6983-4b48-9349-6e0111b313fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ingest pipeline\n",
    "\n",
    "client.ingest.put_pipeline( \n",
    "    id=\"plagiarism-checker-pipeline\",\n",
    "    processors = [\n",
    "    {\n",
    "      \"inference\": { #for ml models - to infer against the data that is being ingested in the pipeline\n",
    "        \"model_id\": \"roberta-base-openai-detector\", #text classification model id\n",
    "        \"target_field\": \"openai-detector\", # Target field for the inference results\n",
    "        \"field_map\": { #Maps the document field names to the known field names of the model.\n",
    "        \"abstract\": \"text_field\" # Field matching our configured trained model input. \n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"inference\": {\n",
    "        \"model_id\": \"sentence-transformers__all-mpnet-base-v2\", #text embedding model \n",
    "        \"target_field\": \"abstract_vector\", # Target field for the inference results\n",
    "        \"field_map\": {\n",
    "        \"abstract\": \"text_field\" # Field matching our configured trained model input. Typically for NLP models, the field name is text_field.\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b53b39e-d74e-4fa8-a364-e2c3caf37418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'plagiarism-checker'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.create(\n",
    "index=\"plagiarism-checker\",\n",
    "mappings={\n",
    "\"properties\": {\n",
    "    \"title\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "            \"keyword\": {\n",
    "                \"type\": \"keyword\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"abstract\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "            \"keyword\": {\n",
    "                \"type\": \"keyword\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"url\": {\n",
    "        \"type\": \"keyword\"\n",
    "    },\n",
    "    \"venue\": {\n",
    "        \"type\": \"keyword\"\n",
    "    },\n",
    "    \"year\": {\n",
    "        \"type\": \"keyword\"\n",
    "    }, \n",
    "    \"abstract_vector.predicted_value\": { # Inference results field, target_field.predicted_value\n",
    "    \"type\": \"dense_vector\", \n",
    "    \"dims\": 768, # embedding_size\n",
    "    \"index\": \"true\", \n",
    "    \"similarity\": \"dot_product\" #  When indexing vectors for approximate kNN search, you need to specify the similarity function for comparing the vectors.\n",
    "         }\n",
    "  }\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "485355e9-b629-49ff-83e5-7582facabd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cfdc3b7-7e4f-4111-997b-c333ac8938ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done indexing documents into `plagiarism-docs` index\n"
     ]
    }
   ],
   "source": [
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/datasets/emnlp2016-2018.json\"\n",
    "\n",
    "# Send a request to the URL and get the response\n",
    "response = urlopen(url)\n",
    "\n",
    "# Load the response data into a JSON object\n",
    "data_json = json.loads(response.read())\n",
    "\n",
    "def create_index_body(doc):\n",
    "    \"\"\" Generate the body for an Elasticsearch document. \"\"\"\n",
    "    return {\n",
    "        \"_index\": \"plagiarism-docs\",\n",
    "        \"_source\": doc,\n",
    "    }\n",
    "\n",
    "# Prepare the documents to be indexed\n",
    "documents = [create_index_body(doc) for doc in data_json]\n",
    "\n",
    "# Use helpers.bulk to index\n",
    "helpers.bulk(client, documents)\n",
    "\n",
    "print(\"Done indexing documents into `plagiarism-docs` index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4297cb0b-ae2e-44f9-811d-27a41c43a858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 26478, 'timed_out': False, 'total': 974, 'updated': 974, 'created': 0, 'deleted': 0, 'batches': 1, 'version_conflicts': 0, 'noops': 0, 'retries': {'bulk': 0, 'search': 0}, 'throttled_millis': 0, 'requests_per_second': -1.0, 'throttled_until_millis': 0, 'failures': []})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.reindex(wait_for_completion=True,\n",
    "               source={\n",
    "                  \"index\": \"plagiarism-docs\"\n",
    "    },\n",
    "               dest= {\n",
    "                  \"index\": \"plagiarism-checker\",\n",
    "                  \"pipeline\": \"plagiarism-checker-pipeline\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f46f17f-660e-4a60-bc62-642fac16852c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "High similarity detected! This might be plagiarism.\n",
      "\n",
      "Most similar document: 'RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes'\n",
      "\n",
      "Abstract: Understanding and reasoning about cooking recipes is a fruitful research direction towards enabling machines to interpret procedural text. In this work, we introduce RecipeQA, a dataset for multimodal comprehension of cooking recipes. It comprises of approximately 20K instructional recipes with multiple modalities such as titles, descriptions and aligned set of images. With over 36K automatically generated question-answer pairs, we design a set of comprehension and reasoning tasks that require joint understanding of images and text, capturing the temporal flow of events and making sense of procedural knowledge. Our preliminary results indicate that RecipeQA will serve as a challenging test bed and an ideal benchmark for evaluating machine comprehension systems. The data and leaderboard are available at http://hucvl.github.io/recipeqa.\n",
      "\n",
      "url: http://aclweb.org/anthology/D18-1166\n",
      "\n",
      "Score:1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#duplicated text - direct plagiarism\n",
    "\n",
    "model_text = 'Understanding and reasoning about cooking recipes is a fruitful research direction towards enabling machines to interpret procedural text. In this work, we introduce RecipeQA, a dataset for multimodal comprehension of cooking recipes. It comprises of approximately 20K instructional recipes with multiple modalities such as titles, descriptions and aligned set of images. With over 36K automatically generated question-answer pairs, we design a set of comprehension and reasoning tasks that require joint understanding of images and text, capturing the temporal flow of events and making sense of procedural knowledge. Our preliminary results indicate that RecipeQA will serve as a challenging test bed and an ideal benchmark for evaluating machine comprehension systems. The data and leaderboard are available at http://hucvl.github.io/recipeqa.'\n",
    "\n",
    "response = client.search(index='plagiarism-checker', size=1,\n",
    "    knn={\n",
    "        \"field\": \"abstract_vector.predicted_value\",\n",
    "        \"k\": 9,\n",
    "        \"num_candidates\": 974,\n",
    "        \"query_vector_builder\": {\n",
    "            \"text_embedding\": {\n",
    "                \"model_id\": \"sentence-transformers__all-mpnet-base-v2\",\n",
    "                \"model_text\": model_text\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    score = hit['_score']\n",
    "    title = hit['_source']['title']\n",
    "    abstract = hit['_source']['abstract']\n",
    "    openai = hit['_source']['openai-detector']['predicted_value']\n",
    "    url = hit['_source']['url']\n",
    "\n",
    "    if score > 0.9:\n",
    "        print(f\"\\nHigh similarity detected! This might be plagiarism.\")\n",
    "        print(f\"\\nMost similar document: '{title}'\\n\\nAbstract: {abstract}\\n\\nurl: {url}\\n\\nScore:{score}\\n\")\n",
    "\n",
    "        if openai == 'Fake':\n",
    "            print(\"This document may have been created by AI.\\n\")\n",
    "\n",
    "    elif score < 0.7:\n",
    "        print(f\"\\nLow similarity detected. This might not be plagiarism.\")\n",
    "\n",
    "        if openai == 'Fake':\n",
    "            print(\"This document may have been created by AI.\\n\")\n",
    "\n",
    "    else:\n",
    "        print(f\"\\nModerate similarity detected.\")\n",
    "        print(f\"\\nMost similar document: '{title}'\\n\\nAbstract: {abstract}\\n\\nurl: {url}\\n\\nScore:{score}\\n\")\n",
    "\n",
    "        if openai == 'Fake':\n",
    "            print(\"This document may have been created by AI.\\n\")\n",
    "\n",
    "ml_client = MlClient(client)\n",
    "\n",
    "model_id = 'roberta-base-openai-detector' #open ai text classification model\n",
    "\n",
    "document = [\n",
    "    {\n",
    "        \"text_field\": model_text\n",
    "    }\n",
    "]\n",
    "\n",
    "ml_response = ml_client.infer_trained_model(model_id=model_id, docs=document)\n",
    "\n",
    "predicted_value = ml_response['inference_results'][0]['predicted_value']\n",
    "\n",
    "if predicted_value == 'Fake':\n",
    "    print(\"Note: The text query you entered may have been generated by AI.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bb5ffb1-bf2e-4a16-869c-2de982736831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "High similarity detected! This might be plagiarism.\n",
      "\n",
      "Most similar document: 'RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes'\n",
      "\n",
      "Abstract: Understanding and reasoning about cooking recipes is a fruitful research direction towards enabling machines to interpret procedural text. In this work, we introduce RecipeQA, a dataset for multimodal comprehension of cooking recipes. It comprises of approximately 20K instructional recipes with multiple modalities such as titles, descriptions and aligned set of images. With over 36K automatically generated question-answer pairs, we design a set of comprehension and reasoning tasks that require joint understanding of images and text, capturing the temporal flow of events and making sense of procedural knowledge. Our preliminary results indicate that RecipeQA will serve as a challenging test bed and an ideal benchmark for evaluating machine comprehension systems. The data and leaderboard are available at http://hucvl.github.io/recipeqa.\n",
      "\n",
      "url: http://aclweb.org/anthology/D18-1166\n",
      "\n",
      "Score:0.9302529\n",
      "\n",
      "Note: The text query you entered may have been generated by AI.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#similar text - paraphrase plagiarism\n",
    "\n",
    "model_text = 'Comprehending and deducing information from culinary instructions represents a promising avenue for research aimed at empowering artificial intelligence to decipher step-by-step text. In this study, we present CuisineInquiry, a database for the multifaceted understanding of cooking guidelines. It encompasses a substantial number of informative recipes featuring various elements such as headings, explanations, and a matched assortment of visuals. Utilizing an extensive set of automatically crafted question-answer pairings, we formulate a series of tasks focusing on understanding and logic that necessitate a combined interpretation of visuals and written content. This involves capturing the sequential progression of events and extracting meaning from procedural expertise. Our initial findings suggest that CuisineInquiry is poised to function as a demanding experimental platform.'\n",
    "\n",
    "response = client.search(index='plagiarism-checker', size=1,\n",
    "    knn={\n",
    "        \"field\": \"abstract_vector.predicted_value\",\n",
    "        \"k\": 9,\n",
    "        \"num_candidates\": 974,\n",
    "        \"query_vector_builder\": {\n",
    "            \"text_embedding\": {\n",
    "                \"model_id\": \"sentence-transformers__all-mpnet-base-v2\",\n",
    "                \"model_text\": model_text\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    score = hit['_score']\n",
    "    title = hit['_source']['title']\n",
    "    abstract = hit['_source']['abstract']\n",
    "    openai = hit['_source']['openai-detector']['predicted_value']\n",
    "    url = hit['_source']['url']\n",
    "\n",
    "    if score > 0.9:\n",
    "        print(f\"\\nHigh similarity detected! This might be plagiarism.\")\n",
    "        print(f\"\\nMost similar document: '{title}'\\n\\nAbstract: {abstract}\\n\\nurl: {url}\\n\\nScore:{score}\\n\")\n",
    "\n",
    "        if openai == 'Fake':\n",
    "            print(\"This document may have been created by AI.\\n\")\n",
    "\n",
    "    elif score < 0.7:\n",
    "        print(f\"\\nLow similarity detected. This might not be plagiarism.\")\n",
    "\n",
    "        if openai == 'Fake':\n",
    "            print(\"This document may have been created by AI.\\n\")\n",
    "\n",
    "    else:\n",
    "        print(f\"\\nModerate similarity detected.\")\n",
    "        print(f\"\\nMost similar document: '{title}'\\n\\nAbstract: {abstract}\\n\\nurl: {url}\\n\\nScore:{score}\\n\")\n",
    "\n",
    "        if openai == 'Fake':\n",
    "            print(\"This document may have been created by AI.\\n\")\n",
    "\n",
    "ml_client = MlClient(client)\n",
    "\n",
    "model_id = 'roberta-base-openai-detector' #open ai text classification model\n",
    "\n",
    "document = [\n",
    "    {\n",
    "        \"text_field\": model_text\n",
    "    }\n",
    "]\n",
    "\n",
    "ml_response = ml_client.infer_trained_model(model_id=model_id, docs=document)\n",
    "\n",
    "predicted_value = ml_response['inference_results'][0]['predicted_value']\n",
    "\n",
    "if predicted_value == 'Fake':\n",
    "    print(\"Note: The text query you entered may have been generated by AI.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5f5aa94-9ca6-4376-9949-ffa914cd976d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Low similarity detected. This might not be plagiarism. 0.6814314\n"
     ]
    }
   ],
   "source": [
    "#different text - not a plagiarism\n",
    "\n",
    "model_text = 'Elasticsearch provides near real-time search and analytics for all types of data.'\n",
    "\n",
    "response = client.search(index='plagiarism-checker', size=1, explain='true',\n",
    "    knn={\n",
    "        \"field\": \"abstract_vector.predicted_value\",\n",
    "        \"k\": 9,\n",
    "        \"num_candidates\": 974,\n",
    "        \"query_vector_builder\": {\n",
    "            \"text_embedding\": {\n",
    "                \"model_id\": \"sentence-transformers__all-mpnet-base-v2\",\n",
    "                \"model_text\": model_text\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    score = hit['_score']\n",
    "    title = hit['_source']['title']\n",
    "    abstract = hit['_source']['abstract']\n",
    "    openai = hit['_source']['openai-detector']['predicted_value']\n",
    "    url = hit['_source']['url']\n",
    "\n",
    "    if score > 0.9:\n",
    "        print(f\"\\nHigh similarity detected! This might be plagiarism.\")\n",
    "        print(f\"\\nMost similar document: '{title}'\\n\\nAbstract: {abstract}\\n\\nurl: {url}\\n\\nScore:{score}\\n\")\n",
    "\n",
    "        if openai == 'Fake':\n",
    "            print(\"This document may have been created by AI.\\n\")\n",
    "\n",
    "    elif score < 0.7:\n",
    "        print(f\"\\nLow similarity detected. This might not be plagiarism. {score}\")\n",
    "\n",
    "        if openai == 'Fake':\n",
    "            print(\"This document may have been created by AI.\\n\")\n",
    "\n",
    "    else:\n",
    "        print(f\"\\nModerate similarity detected.\")\n",
    "        print(f\"\\nMost similar document: '{title}'\\n\\nAbstract: {abstract}\\n\\nurl: {url}\\n\\nScore:{score}\\n\")\n",
    "\n",
    "        if openai == 'Fake':\n",
    "            print(\"This document may have been created by AI.\\n\")\n",
    "      \n",
    "ml_client = MlClient(client)\n",
    "\n",
    "model_id = 'roberta-base-openai-detector' #open ai text classification model\n",
    "\n",
    "document = [\n",
    "    {\n",
    "        \"text_field\": model_text\n",
    "    }\n",
    "]\n",
    "\n",
    "ml_response = ml_client.infer_trained_model(model_id=model_id, docs=document)\n",
    "\n",
    "predicted_value = ml_response['inference_results'][0]['predicted_value']\n",
    "\n",
    "if predicted_value == 'Fake':\n",
    "    print(\"Note: The text query you entered may have been generated by AI.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f51d05-8a9e-4180-8906-da56ab329014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
