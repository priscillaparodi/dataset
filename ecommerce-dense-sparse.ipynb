{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6ae92150-a44b-4899-80f3-0ba7df8ac595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elasticsearch==8.9\n",
      "  Downloading elasticsearch-8.9.0-py3-none-any.whl (395 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.5/395.5 kB\u001b[0m \u001b[31m703.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: elastic-transport<9,>=8 in ./anaconda3/lib/python3.10/site-packages (from elasticsearch==8.9) (8.4.0)\n",
      "Requirement already satisfied: urllib3<2,>=1.26.2 in ./anaconda3/lib/python3.10/site-packages (from elastic-transport<9,>=8->elasticsearch==8.9) (1.26.15)\n",
      "Requirement already satisfied: certifi in ./anaconda3/lib/python3.10/site-packages (from elastic-transport<9,>=8->elasticsearch==8.9) (2022.12.7)\n",
      "Installing collected packages: elasticsearch\n",
      "  Attempting uninstall: elasticsearch\n",
      "    Found existing installation: elasticsearch 8.6.2\n",
      "    Uninstalling elasticsearch-8.6.2:\n",
      "      Successfully uninstalled elasticsearch-8.6.2\n",
      "Successfully installed elasticsearch-8.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install elasticsearch==8.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c29119c-297d-44bf-b892-4d880bd91951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip -q install eland elasticsearch sentence_transformers transformers torch==1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaf90bc8-647e-4ada-9aa9-5cb9e60762b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priscilla/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/5r/774p5f6x3jb5md2ycsn04blc0000gn/T/ipykernel_3557/982692874.py:7: DeprecationWarning: Importing from the 'elasticsearch.client' module is deprecated. Instead use 'elasticsearch' module for importing the client.\n",
      "  from elasticsearch.client import MlClient\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from pathlib import Path\n",
    "from eland.ml.pytorch import PyTorchModel\n",
    "from eland.ml.pytorch.transformers import TransformerModel\n",
    "from elasticsearch.client import MlClient\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6907a2bf-4927-428e-9ca8-9df3dd35a2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Elastic Cloud ID:   ········\n",
      "Enter Elastic password:   ········\n"
     ]
    }
   ],
   "source": [
    "# Found in the 'Manage Deployment' page\n",
    "CLOUD_ID = getpass.getpass('Enter Elastic Cloud ID:  ')\n",
    "\n",
    "# Password for the 'elastic' user generated by Elasticsearch\n",
    "ELASTIC_PASSWORD = getpass.getpass('Enter Elastic password:  ')\n",
    "\n",
    "# Create the client instance\n",
    "client = Elasticsearch(\n",
    "    cloud_id=CLOUD_ID,\n",
    "    basic_auth=(\"elastic\", ELASTIC_PASSWORD),\n",
    "    request_timeout=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f6f3f5a-2b93-4a0c-93c8-c887ca80f687",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 104/104 [04:28<00:00,  2.58s/ parts]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'assignment': {'task_parameters': {'model_id': 'sentence-transformers__all-mpnet-base-v2',\n",
       "   'deployment_id': 'sentence-transformers__all-mpnet-base-v2',\n",
       "   'model_bytes': 435655937,\n",
       "   'threads_per_allocation': 1,\n",
       "   'number_of_allocations': 1,\n",
       "   'queue_capacity': 1024,\n",
       "   'cache_size': '435655937b',\n",
       "   'priority': 'normal'},\n",
       "  'routing_table': {},\n",
       "  'assignment_state': 'starting',\n",
       "  'reason': 'No ML nodes exist in the cluster',\n",
       "  'start_time': '2023-07-27T21:49:03.733791449Z',\n",
       "  'max_assigned_allocations': 0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model name from Hugging Face and task type\n",
    "# sentence-transformers model\n",
    "hf_model_id='sentence-transformers/all-mpnet-base-v2'\n",
    "tm = TransformerModel(hf_model_id, \"text_embedding\")\n",
    "\n",
    "#set the modelID as it is named in Elasticsearch\n",
    "es_model_id = tm.elasticsearch_model_id()\n",
    "\n",
    "# Download the model from Hugging Face\n",
    "tmp_path = \"models\"\n",
    "Path(tmp_path).mkdir(parents=True, exist_ok=True)\n",
    "model_path, config, vocab_path = tm.save(tmp_path)\n",
    "\n",
    "# Load the model into Elasticsearch\n",
    "ptm = PyTorchModel(client, es_model_id)\n",
    "ptm.import_model(model_path=model_path, config_path=None, vocab_path=vocab_path, config=config)\n",
    "\n",
    "# Start the model\n",
    "s = MlClient.start_trained_model_deployment(client, model_id=es_model_id)\n",
    "s.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e115bd0-e758-44db-b5b9-96217af472c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'ecommerce'})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.create(\n",
    "    index=\"ecommerce\",\n",
    "    mappings= {\n",
    "    \"properties\": {\n",
    "      \"product\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"description\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"category\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "  }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6739f55b-6983-4b48-9349-6e0111b313fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating an ingest pipeline with inference processors to use ELSER (sparse) and all-mpnet-base-v2 (dense) to infer against data that will be ingested in the pipeline.\n",
    "\n",
    "client.ingest.put_pipeline( \n",
    "    id=\"ecommerce-pipeline\",\n",
    "    processors = [\n",
    "    {\n",
    "      \"inference\": {\n",
    "        \"model_id\": \".elser_model_1\",\n",
    "        \"target_field\": \"ml\",\n",
    "        \"field_map\": {\n",
    "          \"description\": \"text_field\"\n",
    "        },\n",
    "        \"inference_config\": {\n",
    "          \"text_expansion\": { # text_expansion inference type (ELSER)\n",
    "            \"results_field\": \"tokens\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"inference\": {\n",
    "        \"model_id\": \"sentence-transformers__all-mpnet-base-v2\",\n",
    "        \"target_field\": \"description_vector\", # Target field for the inference results\n",
    "        \"field_map\": {\n",
    "          \"description\": \"text_field\" # Field matching our configured trained model input. Typically for NLP models, the field name is text_field.\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b53b39e-d74e-4fa8-a364-e2c3caf37418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'ecommerce-search'})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX = 'ecommerce-search'\n",
    "client.indices.create(\n",
    "            index=INDEX,\n",
    "            settings={\n",
    "                \"index\": {\n",
    "                    \"number_of_shards\": 1,\n",
    "                    \"number_of_replicas\": 1\n",
    "                }\n",
    "            },\n",
    "            mappings={\n",
    "# Saving disk space by excluding the ELSER tokens and the dense_vector field from document source.\n",
    "# Note: That should only be applied if you are certain that reindexing will not be required in the future.\n",
    "            \"_source\" : {\n",
    "            \"excludes\": [\"ml.tokens\",\"description_vector.predicted_value\"]\n",
    "           }, \n",
    "        \"properties\": {\n",
    "        \"product\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"description\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"category\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"ml.tokens\": { # The name of the field to contain the generated tokens.\n",
    "        \"type\": \"rank_features\" # ELSER output must be ingested into a field with the rank_features field type.\n",
    "      }, \n",
    "     \"description_vector.predicted_value\": { # Inference results field, target_field.predicted_value\n",
    "     \"type\": \"dense_vector\", \n",
    "     \"dims\": 768, # The all-mpnet-base-v2 model has embedding_size of 768, so dims is set to 768.\n",
    "     \"index\": \"true\", \n",
    "     \"similarity\": \"dot_product\" #  When indexing vectors for approximate kNN search, you need to specify the similarity function for comparing the vectors.\n",
    " }\n",
    "  }\n",
    " \n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3cfdc3b7-7e4f-4111-997b-c333ac8938ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done indexing documents into `ecommerce` index\n"
     ]
    }
   ],
   "source": [
    "# Ecommerce dataset\n",
    "url = \"https://raw.githubusercontent.com/priscillaparodi/dataset/main/products-ecommerce.json\"\n",
    "\n",
    "response = urlopen(url)\n",
    "\n",
    "# Load the response data into a JSON object\n",
    "data_json = json.loads(response.read())\n",
    "\n",
    "def create_index_body(doc):\n",
    "    \"\"\" Generate the body for an Elasticsearch document. \"\"\"\n",
    "    return {\n",
    "        \"_index\": \"ecommerce\",\n",
    "        \"_source\": doc,\n",
    "    }\n",
    "\n",
    "# Prepare the documents to be indexed\n",
    "documents = [create_index_body(doc) for doc in data_json]\n",
    "\n",
    "# Use helpers.bulk to index\n",
    "helpers.bulk(client, documents)\n",
    "\n",
    "print(\"Done indexing documents into `ecommerce` index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4297cb0b-ae2e-44f9-811d-27a41c43a858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 18181, 'timed_out': False, 'total': 2495, 'updated': 0, 'created': 2495, 'deleted': 0, 'batches': 3, 'version_conflicts': 0, 'noops': 0, 'retries': {'bulk': 0, 'search': 0}, 'throttled_millis': 0, 'requests_per_second': -1.0, 'throttled_until_millis': 0, 'failures': []})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reindex data from one index 'source' to another 'dest' with the 'ecommerce-pipeline' pipeline.\n",
    "\n",
    "client.reindex(wait_for_completion=True,\n",
    "               source={\n",
    "                  \"index\": \"ecommerce\"\n",
    "    },\n",
    "               dest= {\n",
    "                  \"index\": \"ecommerce-search\",\n",
    "                  \"pipeline\": \"ecommerce-pipeline\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "36ab4628-b611-4a6d-884e-4d2332066bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BM25:\n",
      "\n",
      "\n",
      "Score: 7.8432913\n",
      "Product: Roland TD-17KVX V-Drums Electronic Drum Kit\n",
      "Category: Musical Instruments\n",
      "Description: is a high-quality electronic drum kit with mesh-head pads, realistic sounds, and a responsive drum module. It is perfect for practice and performance.\n",
      "\n",
      "\n",
      "Score: 7.459086\n",
      "Product: Dremel Digilab 3D20 3D Printer\n",
      "Category: 3D Printers and Accessories\n",
      "Description: is a reliable and compact 3D printer, perfect for educational use and beginners.\n",
      "\n",
      "\n",
      "Score: 7.2666483\n",
      "Product: Black Diamond Momentum Climbing Harness\n",
      "Category: Sports Equipment\n",
      "Description: is a comfortable and lightweight climbing harness designed for both beginners and experienced climbers.\n",
      "\n",
      "\n",
      "KNN:\n",
      "\n",
      "\n",
      "Score: 0.80521715\n",
      "Product: Pearl Roadshow RS525SC Drum Set\n",
      "Category: Musical Instruments\n",
      "Description: is an entry-level drum set with poplar shells and double-braced hardware. It is perfect for beginner drummers.\n",
      "\n",
      "\n",
      "Score: 0.7987119\n",
      "Product: Roland TD-17KVX V-Drums Electronic Drum Kit\n",
      "Category: Musical Instruments\n",
      "Description: is a high-quality electronic drum kit with mesh-head pads, realistic sounds, and a responsive drum module. It is perfect for practice and performance.\n",
      "\n",
      "\n",
      "Score: 0.79190445\n",
      "Product: Pearl Decade Maple Drum Set\n",
      "Category: Musical Instruments\n",
      "Description: is a high-quality drum set with all-maple shells and professional hardware. It is suitable for intermediate and advanced drummers.\n",
      "\n",
      "\n",
      "ELSER:\n",
      "\n",
      "\n",
      "Score: 16.742073\n",
      "Product: Pearl Roadshow RS525SC Drum Set\n",
      "Category: Musical Instruments\n",
      "Description: is an entry-level drum set with poplar shells and double-braced hardware. It is perfect for beginner drummers.\n",
      "\n",
      "\n",
      "Score: 16.496183\n",
      "Product: Pearl Export EXX Drum Set\n",
      "Category: Musical Instruments\n",
      "Description: is a reliable drum set with poplar shells and excellent hardware. It is suitable for beginner and intermediate drummers.\n",
      "\n",
      "\n",
      "Score: 15.720047\n",
      "Product: Pearl Decade Maple Drum Set\n",
      "Category: Musical Instruments\n",
      "Description: is a high-quality drum set with all-maple shells and professional hardware. It is suitable for intermediate and advanced drummers.\n",
      "\n",
      "\n",
      "Hybrid Search\n",
      "\n",
      "\n",
      "BM25 + KNN:\n",
      "\n",
      "\n",
      "Score: 8.6470585\n",
      "Product: Roland TD-17KVX V-Drums Electronic Drum Kit\n",
      "Category: Musical Instruments\n",
      "Description: is a high-quality electronic drum kit with mesh-head pads, realistic sounds, and a responsive drum module. It is perfect for practice and performance.\n",
      "\n",
      "\n",
      "Score: 7.958804\n",
      "Product: STX Stallion 200 Lacrosse Starter Set\n",
      "Category: Sports Equipment\n",
      "Description: is a complete lacrosse starter set for beginners, including stick, gloves, and protective gear.\n",
      "\n",
      "\n",
      "Score: 7.459086\n",
      "Product: Dremel Digilab 3D20 3D Printer\n",
      "Category: 3D Printers and Accessories\n",
      "Description: is a reliable and compact 3D printer, perfect for educational use and beginners.\n",
      "\n",
      "\n",
      "BM25 + KNN (RRF):\n",
      "\n",
      "\n",
      "Rank: 1\n",
      "Product: Roland TD-17KVX V-Drums Electronic Drum Kit\n",
      "Category: Musical Instruments\n",
      "Description: is a high-quality electronic drum kit with mesh-head pads, realistic sounds, and a responsive drum module. It is perfect for practice and performance.\n",
      "\n",
      "\n",
      "Rank: 2\n",
      "Product: Pearl Roadshow RS525SC Drum Set\n",
      "Category: Musical Instruments\n",
      "Description: is an entry-level drum set with poplar shells and double-braced hardware. It is perfect for beginner drummers.\n",
      "\n",
      "\n",
      "Rank: 3\n",
      "Product: Pearl Export EXX Drum Set\n",
      "Category: Musical Instruments\n",
      "Description: is a reliable drum set with poplar shells and excellent hardware. It is suitable for beginner and intermediate drummers.\n",
      "\n",
      "\n",
      "BM25 + ELSER:\n",
      "\n",
      "\n",
      "Score: 23.187035\n",
      "Product: Pearl Export EXX Drum Set\n",
      "Category: Musical Instruments\n",
      "Description: is a reliable drum set with poplar shells and excellent hardware. It is suitable for beginner and intermediate drummers.\n",
      "\n",
      "\n",
      "Score: 23.063519\n",
      "Product: Pearl Roadshow RS525SC Drum Set\n",
      "Category: Musical Instruments\n",
      "Description: is an entry-level drum set with poplar shells and double-braced hardware. It is perfect for beginner drummers.\n",
      "\n",
      "\n",
      "Score: 21.374126\n",
      "Product: Roland TD-17KVX V-Drums Electronic Drum Kit\n",
      "Category: Musical Instruments\n",
      "Description: is a high-quality electronic drum kit with mesh-head pads, realistic sounds, and a responsive drum module. It is perfect for practice and performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of results\n",
    "\n",
    "# BM25\n",
    "\n",
    "print(f\"\\nBM25:\\n\")\n",
    "\n",
    "response1 = client.search(size=3,\n",
    "    index=\"ecommerce-search\",\n",
    "    query= {\n",
    "            \"match\": {\n",
    "                    \"description\" : {  \n",
    "                    \"query\": \"Drum for beginners\"\n",
    "                        }\n",
    "                    }\n",
    "        }\n",
    ")\n",
    "hits = response1['hits']['hits']\n",
    "\n",
    "if not hits:\n",
    "    print(\"BM25 Result: No matches found\")\n",
    "else:\n",
    "    for hit in hits:\n",
    "        score = hit['_score']\n",
    "        product = hit['_source']['product']\n",
    "        category = hit['_source']['category']\n",
    "        description = hit['_source']['description']\n",
    "        print(f\"\\nScore: {score}\\nProduct: {product}\\nCategory: {category}\\nDescription: {description}\\n\")\n",
    "\n",
    "# KNN\n",
    "\n",
    "print(f\"\\nKNN:\\n\")\n",
    "\n",
    "response2 = client.search(index='ecommerce-search', size=3,\n",
    "            knn={\n",
    "            \"field\": \"description_vector.predicted_value\",\n",
    "            \"k\": 49,\n",
    "            \"num_candidates\": 2495,\n",
    "            \"query_vector_builder\": {\n",
    "            \"text_embedding\": { \n",
    "            \"model_id\": \"sentence-transformers__all-mpnet-base-v2\", \n",
    "            \"model_text\": \"A drum for someone who is beginning to play.\" \n",
    "      }\n",
    "    }\n",
    "            }\n",
    ")\n",
    "\n",
    "for hit in response2['hits']['hits']:\n",
    "    \n",
    "    score = hit['_score']\n",
    "    product = hit['_source']['product']\n",
    "    category = hit['_source']['category']\n",
    "    description = hit['_source']['description']\n",
    "    print(f\"\\nScore: {score}\\nProduct: {product}\\nCategory: {category}\\nDescription: {description}\\n\")\n",
    "\n",
    "# ELSER\n",
    "\n",
    "print(f\"\\nELSER:\\n\")\n",
    "\n",
    "response3 = client.search(index='ecommerce-search', size=3,\n",
    "              query={\n",
    "                  \"text_expansion\": {\n",
    "                  \"ml.tokens\": {\n",
    "                      \"model_id\":\".elser_model_1\",\n",
    "                      \"model_text\":\"A drum for someone who is beginning to play.\"                \n",
    "        }\n",
    "    }\n",
    "}\n",
    ")\n",
    "\n",
    "for hit in response3['hits']['hits']:\n",
    "\n",
    "    score = hit['_score']\n",
    "    product = hit['_source']['product']\n",
    "    category = hit['_source']['category']\n",
    "    description = hit['_source']['description']\n",
    "    print(f\"\\nScore: {score}\\nProduct: {product}\\nCategory: {category}\\nDescription: {description}\\n\")\n",
    "\n",
    "print(f\"\\nHybrid Search\\n\")\n",
    "\n",
    "# BM25 + KNN\n",
    "\n",
    "print(f\"\\nBM25 + KNN:\\n\")\n",
    "\n",
    "response4 = client.search(index='ecommerce-search', size=3,\n",
    "              query={\n",
    "             \"match\": {\n",
    "             \"description\" : {  \n",
    "             \"query\": \"Drum for beginners\",\n",
    "              \"boost\": 1\n",
    "                        }\n",
    "                        }                 \n",
    "                   \n",
    "},\n",
    "            knn={\n",
    "            \"field\": \"description_vector.predicted_value\",\n",
    "            \"k\": 49,\n",
    "            \"num_candidates\": 2495,\n",
    "            \"boost\": 1,\n",
    "            \"query_vector_builder\": {\n",
    "            \"text_embedding\": { \n",
    "            \"model_id\": \"sentence-transformers__all-mpnet-base-v2\", \n",
    "            \"model_text\": \"A drum for someone who is beginning to play\" \n",
    "      }\n",
    "    }\n",
    "            }\n",
    ")\n",
    "\n",
    "for hit in response4['hits']['hits']:\n",
    "\n",
    "    score = hit['_score']\n",
    "    product = hit['_source']['product']\n",
    "    category = hit['_source']['category']\n",
    "    description = hit['_source']['description']\n",
    "    print(f\"\\nScore: {score}\\nProduct: {product}\\nCategory: {category}\\nDescription: {description}\\n\")\n",
    "\n",
    "# BM25 + KNN (RRF)\n",
    "\n",
    "print(f\"\\nBM25 + KNN (RRF):\\n\")\n",
    "\n",
    "response5 = client.search(index='ecommerce-search', size=3,\n",
    "             query = {\n",
    "             \"match\": {\n",
    "             \"description\" : {  \n",
    "             \"query\": \"Drum for beginners\",\n",
    "                        }\n",
    "                        }                 \n",
    "                   \n",
    "},\n",
    "             knn = {\n",
    "            \"field\": \"description_vector.predicted_value\",\n",
    "            \"k\": 49,\n",
    "            \"num_candidates\": 2495,\n",
    "            \"query_vector_builder\": {\n",
    "            \"text_embedding\": { \n",
    "            \"model_id\": \"sentence-transformers__all-mpnet-base-v2\", \n",
    "            \"model_text\": \"A drum for someone who is beginning to play\" \n",
    "      }\n",
    "    }\n",
    "            },\n",
    "        rank = {\n",
    "        \"rrf\": {\n",
    "            \"window_size\": 2495,\n",
    "            \"rank_constant\": 10\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "for hit in response5['hits']['hits']:\n",
    "    \n",
    "    rank = hit['_rank']\n",
    "    category = hit['_source']['category']\n",
    "    product = hit['_source']['product']\n",
    "    description = hit['_source']['description']\n",
    "    print(f\"\\nRank: {rank}\\nProduct: {product}\\nCategory: {category}\\nDescription: {description}\\n\")\n",
    "\n",
    "# BM25 + ELSER\n",
    "# Note: Client is not compatible with Elastic 8.9 to use sub_searches parameter. Not adding RRF, for now.\n",
    "# Using compound query - 'should' appear in the matching document.\n",
    "\n",
    "print(f\"\\nBM25 + ELSER:\\n\")\n",
    "\n",
    "response6 = client.search(index='ecommerce-search', size=3,\n",
    "\n",
    "        query= {\n",
    "            \"bool\": {\n",
    "                \"should\": [\n",
    "                    {\n",
    "                        \"match\": {\n",
    "                            \"description\" : {  \n",
    "                            \"query\": \"Drum for beginners\",\n",
    "                            \"boost\": 1\n",
    "                        }\n",
    "                        }\n",
    "                    },                   \n",
    "                    {\n",
    "                        \"text_expansion\": {\n",
    "                            \"ml.tokens\": {\n",
    "                                \"model_id\": \".elser_model_1\",\n",
    "                                \"model_text\": \"A drum for someone who is beginning to play\",\n",
    "                                \"boost\": 1\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "\n",
    ")\n",
    "\n",
    "for hit in response6['hits']['hits']:\n",
    "\n",
    "    score = hit['_score']\n",
    "    product = hit['_source']['product']\n",
    "    category = hit['_source']['category']\n",
    "    description = hit['_source']['description']\n",
    "    print(f\"\\nScore: {score}\\nProduct: {product}\\nCategory: {category}\\nDescription: {description}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8699c377-0268-42a1-8192-a3b4ecc772e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
